{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17JtnYtxvsJC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
        "\n",
        "class RSSContentExtractor:\n",
        "    def __init__(self, rss_file_path, output_file='output.txt', max_workers=5):\n",
        "        self.rss_file_path = rss_file_path\n",
        "        self.output_file = output_file\n",
        "        self.max_workers = max_workers\n",
        "\n",
        "    def load_rss_file(self):\n",
        "        if not os.path.exists(self.rss_file_path):\n",
        "            logging.error(f\"RSS file not found: {self.rss_file_path}\")\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            tree = ET.parse(self.rss_file_path)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Handles different RSS XML structures\n",
        "            links = root.findall('.//link')\n",
        "\n",
        "            if not links:\n",
        "                logging.warning(\"No links found in RSS file\")\n",
        "                return []\n",
        "\n",
        "            return [link.text for link in links if link.text]\n",
        "\n",
        "        except ET.ParseError:\n",
        "            logging.error(\"Invalid XML structure\")\n",
        "            return []\n",
        "\n",
        "    def fetch_content(self, url):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            return response.text\n",
        "        except requests.RequestException as e:\n",
        "            logging.error(f\"Error fetching {url}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_contents(self):\n",
        "        links = self.load_rss_file()\n",
        "\n",
        "        if not links:\n",
        "            logging.error(\"No links available to process\")\n",
        "            return\n",
        "\n",
        "        with open(self.output_file, 'w', encoding='utf-8') as outfile:\n",
        "            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
        "                future_to_url = {executor.submit(self.fetch_content, link): link for link in links}\n",
        "\n",
        "                for future in as_completed(future_to_url):\n",
        "                    url = future_to_url[future]\n",
        "                    try:\n",
        "                        content = future.result()\n",
        "                        if content:\n",
        "                            outfile.write(f\"URL: {url}\\n{content}\\n{'='*50}\\n\")\n",
        "                    except Exception as e:\n",
        "                        logging.error(f\"Error processing {url}: {e}\")\n",
        "\n",
        "def main():\n",
        "    rss_file = 'feed.xml'  # Replace with your RSS XML file path\n",
        "    extractor = RSSContentExtractor(rss_file)\n",
        "    extractor.extract_contents()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}